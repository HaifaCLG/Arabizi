{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPIF8U2ycKiZh//njKe6jN6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d7da8c8ac9e442ab9bad9edef56e295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d132fe2247dc43dca4f35af1b60e92f9",
              "IPY_MODEL_6e9a1488a01e4dfc9d40f96c0edb36ba",
              "IPY_MODEL_d6570ca107f846889861b63a5a3a96f2"
            ],
            "layout": "IPY_MODEL_d114ae1ebd6e40d4a746a953541d3e74"
          }
        },
        "d132fe2247dc43dca4f35af1b60e92f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2270afe4bf524e0eafd3104f4a746804",
            "placeholder": "​",
            "style": "IPY_MODEL_c68944c92d89465087999ca538c6b281",
            "value": "Downloading: 100%"
          }
        },
        "6e9a1488a01e4dfc9d40f96c0edb36ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8556c65c66042b7be8bd58b5ff39356",
            "max": 871891,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4405954167aa4330b55cbb2e3e4c4d8c",
            "value": 871891
          }
        },
        "d6570ca107f846889861b63a5a3a96f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02ce95b164b443739c0df61ea642c64c",
            "placeholder": "​",
            "style": "IPY_MODEL_510ff98876aa4902abd7e08d08b58c6c",
            "value": " 872k/872k [00:01&lt;00:00, 886kB/s]"
          }
        },
        "d114ae1ebd6e40d4a746a953541d3e74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2270afe4bf524e0eafd3104f4a746804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c68944c92d89465087999ca538c6b281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8556c65c66042b7be8bd58b5ff39356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4405954167aa4330b55cbb2e3e4c4d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02ce95b164b443739c0df61ea642c64c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "510ff98876aa4902abd7e08d08b58c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "197c19786e44457daf2c1357be18718f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf9eafb5a3be4e37be704f0f292d3be7",
              "IPY_MODEL_46233587b72d4c7bb3ffd377352653ca",
              "IPY_MODEL_7d2157845aac48be9d5cd010c1988e26"
            ],
            "layout": "IPY_MODEL_5703d6092c5644588a12773b691c6dc0"
          }
        },
        "bf9eafb5a3be4e37be704f0f292d3be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b85d8577633242d2a7162fea78f78d3f",
            "placeholder": "​",
            "style": "IPY_MODEL_298a130122e540a7b55e0df8d95049d1",
            "value": "Downloading: 100%"
          }
        },
        "46233587b72d4c7bb3ffd377352653ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bea6b88b115f4c4085e65825eb322ae2",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c8ef1d769c24deab3ad1650cfa2bcfc",
            "value": 28
          }
        },
        "7d2157845aac48be9d5cd010c1988e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32eb870acd984b2da85804377ddf2f1b",
            "placeholder": "​",
            "style": "IPY_MODEL_e860c65ccb8c4cf7adf3739ffec40c3a",
            "value": " 28.0/28.0 [00:00&lt;00:00, 914B/s]"
          }
        },
        "5703d6092c5644588a12773b691c6dc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b85d8577633242d2a7162fea78f78d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "298a130122e540a7b55e0df8d95049d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bea6b88b115f4c4085e65825eb322ae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c8ef1d769c24deab3ad1650cfa2bcfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32eb870acd984b2da85804377ddf2f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e860c65ccb8c4cf7adf3739ffec40c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "421f47089e954ba1bc124a2a764ce89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26ceeca2e37e4a2aa5c2f37399df98f6",
              "IPY_MODEL_a03ef6856dc947249d9476cb7300a5c9",
              "IPY_MODEL_ad07e4332d5a417d8008f5d1bf9335be"
            ],
            "layout": "IPY_MODEL_dd6e491694144cc690bb7af7bf9df09b"
          }
        },
        "26ceeca2e37e4a2aa5c2f37399df98f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6b283482d5148e49a10bf080b871c36",
            "placeholder": "​",
            "style": "IPY_MODEL_3ebd884f4c874e6d935a3c0000b13de6",
            "value": "Downloading: 100%"
          }
        },
        "a03ef6856dc947249d9476cb7300a5c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f48fd215a5342f88c88fd3eff63abf8",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6ab4f6cd2ce4133957e5af3fcbdd7ac",
            "value": 625
          }
        },
        "ad07e4332d5a417d8008f5d1bf9335be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b21f7f9ff3ff441c918ecd7abf29e77f",
            "placeholder": "​",
            "style": "IPY_MODEL_18faa52bea8040348e9043ae468eee35",
            "value": " 625/625 [00:00&lt;00:00, 21.4kB/s]"
          }
        },
        "dd6e491694144cc690bb7af7bf9df09b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6b283482d5148e49a10bf080b871c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ebd884f4c874e6d935a3c0000b13de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f48fd215a5342f88c88fd3eff63abf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6ab4f6cd2ce4133957e5af3fcbdd7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b21f7f9ff3ff441c918ecd7abf29e77f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18faa52bea8040348e9043ae468eee35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaifaCLG/Arabizi/blob/main/langdetect_lstm_bert_crf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFBW66Hwdsmy",
        "outputId": "2828a32a-ab15-49b5-fc7b-7477de5a294b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.4.0\n",
            "  Downloading torchtext-0.4.0-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (4.64.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0) (2022.9.24)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.4.0) (4.1.1)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "Successfully installed torchtext-0.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 32.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 75.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 44.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=c6e10a48eb6fe69c6cb99fb4d4d6a65cad2885c9e6599b3de9b376086772de5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.4.0\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchtext import data\n",
        "from torch.utils.data import DataLoader\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer,BertModel\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "!pip install seqeval\n",
        "from seqeval.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting my drive on colab, in order to get my annotated file and other essential files"
      ],
      "metadata": {
        "id": "JcfIePXJjMjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "import sys\n",
        "from pathlib import Path\n",
        "base=Path('/content/gdrive/MyDrive/Arabizi-project')\n",
        "sys.path.append(str(base))\n",
        "print(base)\n",
        "!cp -r \"{base}\" ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XetLdkc1eA2T",
        "outputId": "1afbe0da-4a3f-4e71-9be3-95db7f7b2b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Arabizi-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell contains the code that prepare the data : tokenizing , making equal size sentences by padding \n",
        "mapping words to numbers \n",
        "make dictionaries from words to numbers and vice versa\n"
      ],
      "metadata": {
        "id": "8p4E16NQjsj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True,add_special_tokens=True)\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "print(device)\n",
        "\n",
        "def get_dict_map_label(data):\n",
        "\n",
        "  vocab=[\"PAD\",\"CLS\",\"SEP\"]+list(set(data['categ'].to_list()))  \n",
        "  index_to_tag = {index: word for index, word in enumerate(vocab)}\n",
        "  tag_to_index = {word: index for index, word in enumerate(vocab)}\n",
        "  return tag_to_index,index_to_tag\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "    def __init__(self,data):\n",
        "        self.data=data\n",
        "        self.srcs,self.tgs=self.tokenize_srcs_tgs()\n",
        "\n",
        "    def split_to_sentences(self,data):\n",
        "      result_sens=[]\n",
        "      result_tags=[]\n",
        "      sen_num=len(data[\"categ\"].tolist())\n",
        "      for i in range(0,sen_num):\n",
        "        original_sen_list=data[\"token\"].tolist()[i]\n",
        "        original_tag_list=data[\"categ\"].tolist()[i]\n",
        "        result_sens.extend([['[CLS]']+original_sen_list+['[SEP]']])\n",
        "        result_tags.extend([['CLS']+original_tag_list+['SEP']])\n",
        "      return result_sens,result_tags\n",
        "\n",
        "    def tokenize_srcs_tgs(self):\n",
        "        srcs,tgs=self.split_to_sentences(self.data)\n",
        "        tokenized_texts_and_labels = [tokenize_and_preserve_labels(sent, labs) for sent, labs in zip(srcs, tgs)]\n",
        "        srcs = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
        "        tgs = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]\n",
        "        tokenized_srcs=[]\n",
        "        tokenized_tgs=[]\n",
        "        for i in range(0,len(srcs)):\n",
        "          tokenized_srcs.append(tokenizer.convert_tokens_to_ids(srcs[i]) )        \n",
        "          tokenized_tgs.append([tag_to_index[w] for w in tgs[i]])\n",
        "        samples = sorted(zip(tokenized_srcs, tokenized_tgs), key=lambda x: len(x[0]))\n",
        "        inputs = [item[0] for item in samples]\n",
        "        targets = [item[1] for item in samples]\n",
        "        return inputs,targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.srcs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return torch.LongTensor(self.srcs[index]),torch.LongTensor(self.tgs[index])\n",
        "\n",
        "\n",
        "\n",
        "import csv\n",
        "#na_filter=False in order to not consider NA words as null\n",
        "labeled_df = pd.read_csv(\"/content/Arabizi-project/words_annotated.csv\",dtype=str,na_filter=False)\n",
        "\n",
        "labeled_data=labeled_df.groupby([\"sen_id\",\"sen_num\"],as_index=False)[\"token\",\"categ\"].agg(lambda x: list(x))\n",
        "tag_to_index,index_to_tag=get_dict_map_label(labeled_df)\n",
        "\n",
        "#collate_fn  padded each batch to the max len in the batch\n",
        "BATCH_SIZE=32\n",
        "def collate_fn(batch):\n",
        "    # batch contains a list of tuples of structure (sequence, target)\n",
        "    inputs = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    if len(inputs)<BATCH_SIZE:  \n",
        "      for i in range(len(inputs),BATCH_SIZE):\n",
        "        inputs.append(torch.tensor([tokenizer.convert_tokens_to_ids('[CLS]'),tokenizer.convert_tokens_to_ids('[SEP]')]))\n",
        "        targets.append(torch.tensor([tag_to_index['CLS'],tag_to_index['SEP']]))\n",
        "    inputs = torch.nn.utils.rnn.pad_sequence(inputs,batch_first=True, padding_value=tokenizer.convert_tokens_to_ids('[PAD]'))\n",
        "    targets = torch.nn.utils.rnn.pad_sequence(targets,batch_first=True, padding_value=tag_to_index['PAD'])\n",
        "    return inputs, targets\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172,
          "referenced_widgets": [
            "8d7da8c8ac9e442ab9bad9edef56e295",
            "d132fe2247dc43dca4f35af1b60e92f9",
            "6e9a1488a01e4dfc9d40f96c0edb36ba",
            "d6570ca107f846889861b63a5a3a96f2",
            "d114ae1ebd6e40d4a746a953541d3e74",
            "2270afe4bf524e0eafd3104f4a746804",
            "c68944c92d89465087999ca538c6b281",
            "c8556c65c66042b7be8bd58b5ff39356",
            "4405954167aa4330b55cbb2e3e4c4d8c",
            "02ce95b164b443739c0df61ea642c64c",
            "510ff98876aa4902abd7e08d08b58c6c",
            "197c19786e44457daf2c1357be18718f",
            "bf9eafb5a3be4e37be704f0f292d3be7",
            "46233587b72d4c7bb3ffd377352653ca",
            "7d2157845aac48be9d5cd010c1988e26",
            "5703d6092c5644588a12773b691c6dc0",
            "b85d8577633242d2a7162fea78f78d3f",
            "298a130122e540a7b55e0df8d95049d1",
            "bea6b88b115f4c4085e65825eb322ae2",
            "0c8ef1d769c24deab3ad1650cfa2bcfc",
            "32eb870acd984b2da85804377ddf2f1b",
            "e860c65ccb8c4cf7adf3739ffec40c3a",
            "421f47089e954ba1bc124a2a764ce89a",
            "26ceeca2e37e4a2aa5c2f37399df98f6",
            "a03ef6856dc947249d9476cb7300a5c9",
            "ad07e4332d5a417d8008f5d1bf9335be",
            "dd6e491694144cc690bb7af7bf9df09b",
            "d6b283482d5148e49a10bf080b871c36",
            "3ebd884f4c874e6d935a3c0000b13de6",
            "1f48fd215a5342f88c88fd3eff63abf8",
            "e6ab4f6cd2ce4133957e5af3fcbdd7ac",
            "b21f7f9ff3ff441c918ecd7abf29e77f",
            "18faa52bea8040348e9043ae468eee35"
          ]
        },
        "id": "64C3-CCVg0W5",
        "outputId": "d71e368b-8a9f-4e0b-a5bd-a8e2167e2992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/872k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d7da8c8ac9e442ab9bad9edef56e295"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "197c19786e44457daf2c1357be18718f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "421f47089e954ba1bc124a2a764ce89a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the model and training "
      ],
      "metadata": {
        "id": "4QW5vyTIn2OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-crf\n",
        "\n",
        "#define parameters\n",
        "embed_size =768*4\n",
        "hidden_size = 400\n",
        "num_layers =2\n",
        "output_dim=len(tag_to_index)\n",
        "\n",
        "\n",
        "from torchcrf import CRF\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, embedding_dim, h_dim, num_layers,out_dim):\n",
        "        super().__init__() \n",
        "        self.num_layers=num_layers\n",
        "        self.h_dim=h_dim\n",
        "        self.bert= BertModel.from_pretrained('bert-base-multilingual-uncased',output_hidden_states = True)\n",
        "        self.crf = CRF(output_dim,batch_first=True)\n",
        "\n",
        "        # Define LSTM layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embed_size,\n",
        "            hidden_size=h_dim,\n",
        "            num_layers=num_layers,\n",
        "            dropout=0.5,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        # Define fc layer\n",
        "        self.fc=nn.Linear(2*h_dim, out_dim)\n",
        "\n",
        "    def forward(self, x, prev_state,segments_ids,tags=None):\n",
        "      self.bert=self.bert.to(device)\n",
        "      self.lstm=self.lstm.to(device)\n",
        "      self.fc=self.fc.to(device)\n",
        "      self.crf=self.crf.to(device)\n",
        "      # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "      self.bert.eval()\n",
        "      with torch.no_grad():\n",
        "        outputs = self.bert(x, segments_ids)\n",
        "        hidden_states = outputs[2]\n",
        "      # Concatenate the tensors for all layers. We use `stack` here to create a new dimension in the tensor.\n",
        "      token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "      token_embeddings = token_embeddings.permute(1,2,0,3)\n",
        "      #token embedding shape: [Batch_size x seq_len x 13 x 768]\n",
        "      Batch_size=token_embeddings.shape[0]\n",
        "      seq_len=token_embeddings.shape[1]    \n",
        "      token_vecs_cat=np.zeros(shape=(Batch_size,seq_len,token_embeddings.shape[3]*4))\n",
        "      token_vecs_cat=torch.FloatTensor(token_vecs_cat).to(device)\n",
        "      b=0\n",
        "      for batch in token_embeddings:\n",
        "        # For each token in the sentence...\n",
        "        # `token` is a [ 13  x 768] tensor\n",
        "        i=0\n",
        "        for token in batch:\n",
        "          #concat the vectors from the last four layers.\n",
        "          token_vecs_cat[b][i]=torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "          i+=1\n",
        "        b+=1\n",
        "      output, state = self.lstm(token_vecs_cat, prev_state)   \n",
        "      output=self.fc(output)\n",
        "      mask=(x!=0)\n",
        "      best_tags = self.crf.decode(output,mask=mask)\n",
        "      crf_loss = -self.crf(output, mask=mask,tags=tags,reduction='mean') if tags is not None else None\n",
        "      return best_tags, crf_loss,state\n",
        "\n",
        "\n",
        "    def init_state(self, batch_size):\n",
        "        return (torch.zeros(2*self.num_layers, batch_size, self.h_dim).to(device),\n",
        "                torch.zeros(2*self.num_layers, batch_size, self.h_dim).to(device))\n",
        "    \n",
        "\n",
        "def train(model, optimizer, scheduler , dataloader, max_epochs=10):\n",
        "  clip_grad=0.5  \n",
        "\n",
        "  for epoch_idx in range(max_epochs):\n",
        "      model.train()\n",
        "      state_h, state_c = model.init_state(BATCH_SIZE)\n",
        "      train_loss=0\n",
        "      for batch_idx,batch in enumerate(dataloader):\n",
        "          X, y = batch\n",
        "          X=X.to(device)\n",
        "          y=y.to(device)       \n",
        "          state_h = state_h.detach()\n",
        "          state_c = state_c.detach()\n",
        "          # Forward pass\n",
        "          # Mark each of the sentence tokens as belonging to sentence \"1\".\n",
        "          segments_ids =torch.tensor([[1] * len(xx) for xx in X])\n",
        "          segments_ids=segments_ids.to(device)\n",
        "          y_pred, batch_loss,(state_h, state_c) = model(X, (state_h, state_c),segments_ids,y)     \n",
        "          optimizer.zero_grad()\n",
        "          loss=batch_loss\n",
        "          train_loss+=loss.item()\n",
        "          # Backward pass\n",
        "          loss.backward()\n",
        "          # Prevent large gradients\n",
        "          if clip_grad > 0:\n",
        "              torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
        "          #updates parameters\n",
        "          optimizer.step() \n",
        "          scheduler.step()\n",
        "\n",
        "\n",
        "\n",
        "      print(f\"Epoch #{epoch_idx}, train loss={train_loss/(len(dataloader)-1):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j32em7NAuohx",
        "outputId": "18ea0362-58b2-4e88-c2b4-9f4e91cf98b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-crf\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the 10-fold cross validation "
      ],
      "metadata": {
        "id": "_f8f7DkOowj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs =4\n",
        "import numpy\n",
        "# join bpe split tokens\n",
        "def join_bpe(token_ids,label_tags):\n",
        "    tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
        "    new_labels = []\n",
        "    for token, label_idx in zip(tokens, label_tags):\n",
        "      if not token.startswith(\"##\") :\n",
        "        new_labels.append(label_idx)\n",
        "    return new_labels\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "batch_size=32\n",
        "#we have the following  6 categ names\n",
        "categ_names = ['Arabizi', 'English', 'French ', 'Arabic ','Trigger', 'Other  ']\n",
        "labeled_dataset=Dataset(labeled_data)\n",
        "def k_fold_cross_validation(k=10):\n",
        "    support=np.array([0]*len(categ_names))\n",
        "    f1_score_arr,precision_score_arr,recall_score_arr=np.array([0.0]*len(categ_names)),np.array([0.0]*len(categ_names)),np.array([0.0]*len(categ_names))\n",
        "    f1_macro,precision_macro,recall_macro=0.0,0.0,0.0\n",
        "    f1_weighted,precision_weighted,recall_weighted=0.0,0.0,0.0\n",
        "    f1_micro,precision_micro,recall_micro=0.0,0.0,0.0\n",
        "    kf=KFold(n_splits=k,shuffle=True)\n",
        "    acc_score=0\n",
        "    for train_idx,test_idx in kf.split(np.arange(len(labeled_dataset))):\n",
        "        train_sample = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "        dev_sample = torch.utils.data.SubsetRandomSampler(test_idx)\n",
        "        train_dl = DataLoader(labeled_dataset,batch_size=BATCH_SIZE,collate_fn=collate_fn,sampler=train_sample)\n",
        "        dev_dl=DataLoader(labeled_dataset, batch_size=BATCH_SIZE,collate_fn=collate_fn,sampler=dev_sample)\n",
        "        model=Model(embed_size,hidden_size,num_layers,output_dim)\n",
        "        optimizer = torch.optim.Adam(model.parameters())\n",
        "        total_steps = len(train_dl) * epochs\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=0,\n",
        "            num_training_steps=total_steps\n",
        "        )\n",
        "        train(model, optimizer,scheduler, train_dl, max_epochs=epochs)\n",
        "        model.eval()\n",
        "        predictions , true_labels,x_total = [], [],[]\n",
        "        state_h, state_c = model.init_state(batch_size)\n",
        "        for batch_idx,batch in enumerate(dev_dl):\n",
        "            X,y=batch\n",
        "            X=X.to(device)\n",
        "            y=y.to(device)\n",
        "            # Forward pass\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach() \n",
        "            # Mark each of the sentence tokens as belonging to sentence \"1\".\n",
        "            segments_ids =torch.tensor([[1] * len(xx) for xx in X])\n",
        "            segments_ids=segments_ids.to(device)  \n",
        "            with torch.no_grad():\n",
        "              y_pred,_, (state_h, state_c) = model(X, (state_h, state_c),segments_ids,y)\n",
        "            label_ids = y.to('cpu').numpy()\n",
        "            # Calculate the accuracy for this batch of  sentences.\n",
        "            predictions.extend(numpy.array(y_pred))\n",
        "            true_labels.extend(label_ids)\n",
        "            x_to_add=X.to('cpu').numpy()\n",
        "            x_total.extend(x_to_add)\n",
        "        x_total=[p_i for p, l in zip(x_total, true_labels)\n",
        "                                  for p_i, l_i in zip(p, l) if index_to_tag[l_i] != \"PAD\" and index_to_tag[l_i] !=\"CLS\" and index_to_tag[l_i] !=\"SEP\"]\n",
        "        pred_tags = [index_to_tag[p_i] for p, l in zip(predictions, true_labels)\n",
        "                                  for p_i, l_i in zip(p, l) if index_to_tag[l_i] != \"PAD\" and index_to_tag[l_i] !=\"CLS\" and index_to_tag[l_i] !=\"SEP\"]\n",
        "        valid_tags = [index_to_tag[l_i] for l in true_labels\n",
        "                                  for l_i in l if index_to_tag[l_i] != \"PAD\" and index_to_tag[l_i] !=\"CLS\" and index_to_tag[l_i] !=\"SEP\"]\n",
        "\n",
        "        y_pred_f=join_bpe(x_total,pred_tags)\n",
        "        y_test_f=join_bpe(x_total,valid_tags)\n",
        "        p, r, f1, s = metrics.precision_recall_fscore_support(y_test_f,y_pred_f,labels=['0','1','2','3','4','5'],average=None)\n",
        "        for i in range(0,len(categ_names)) :\n",
        "            precision_score_arr[i]+=p[i]\n",
        "            f1_score_arr[i]+=f1[i]\n",
        "            recall_score_arr[i]+=r[i]\n",
        "            support[i]+=s[i]\n",
        "        acc_score+=metrics.accuracy_score(y_test_f,y_pred_f)\n",
        "        p, r, f1, _ = metrics.precision_recall_fscore_support(y_test_f,y_pred_f,average='macro')\n",
        "        precision_macro+=p\n",
        "        recall_macro+=r\n",
        "        f1_macro+=f1\n",
        "        p, r, f1, _ = metrics.precision_recall_fscore_support(y_test_f,y_pred_f,average='micro')\n",
        "        precision_micro+=p\n",
        "        recall_micro+=r\n",
        "        f1_micro+=f1\n",
        "        p, r, f1, _ = metrics.precision_recall_fscore_support(y_test_f,y_pred_f,average='weighted')\n",
        "        precision_weighted+=p\n",
        "        recall_weighted+=r\n",
        "        f1_weighted+=f1\n",
        "        total_supp=sum(support)\n",
        "    precision_macro=precision_macro/k\n",
        "    recall_macro=recall_macro/k\n",
        "    f1_macro=f1_macro/k\n",
        "    precision_weighted=precision_weighted/k\n",
        "    recall_weighted=recall_weighted/k\n",
        "    f1_weighted=f1_weighted/k\n",
        "    precision_micro=precision_micro/k\n",
        "    recall_micro=recall_micro/k\n",
        "    f1_micro=f1_micro/k\n",
        "    print(\"---- {0} fold cross validation of the model----\".format(k))\n",
        "    print(acc_score/k)\n",
        "    print('Category     precision    recall      f1-score      support')\n",
        "    for i in range(0, len(categ_names)):\n",
        "        precision_score=precision_score_arr[i]/k\n",
        "        recall_score=recall_score_arr[i]/k\n",
        "        f1_score=f1_score_arr[i]/k\n",
        "        print(' {0}  :  {1:.2f}         {2:.2f}      {3:.2f}        {4}  '.format(categ_names[i],precision_score,recall_score,f1_score,support[i]))\n",
        "    print('micro avg  : {0:.2f}         {1:.2f}      {2:.2f}        {3} '.format(precision_micro,recall_micro,f1_micro,total_supp))\n",
        "    print('macro avg  : {0:.2f}         {1:.2f}      {2:.2f}        {3} '.format(precision_macro,recall_macro,f1_macro,total_supp))\n",
        "    print('weighted avg:{0:.2f}         {1:.2f}      {2:.2f}        {3} '.format(precision_weighted,recall_weighted,f1_weighted,total_supp))\n",
        "\n",
        "k_fold_cross_validation(k=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q8MfNQ7TCUd",
        "outputId": "83d21848-13c3-4fb7-e106-47f0ef4838c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0, train loss=7.6519\n",
            "Epoch #1, train loss=3.2749\n",
            "Epoch #2, train loss=2.6312\n",
            "Epoch #3, train loss=2.0244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0, train loss=7.5056\n",
            "Epoch #1, train loss=3.2886\n",
            "Epoch #2, train loss=2.4861\n",
            "Epoch #3, train loss=1.8937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0, train loss=7.6390\n",
            "Epoch #1, train loss=3.3114\n",
            "Epoch #2, train loss=2.5828\n",
            "Epoch #3, train loss=1.9920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0, train loss=7.4791\n",
            "Epoch #1, train loss=3.2577\n",
            "Epoch #2, train loss=2.5151\n",
            "Epoch #3, train loss=1.9266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0, train loss=8.0114\n",
            "Epoch #1, train loss=3.3504\n",
            "Epoch #2, train loss=2.4815\n",
            "Epoch #3, train loss=1.9419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0, train loss=7.3652\n",
            "Epoch #1, train loss=3.2422\n",
            "Epoch #2, train loss=2.4943\n",
            "Epoch #3, train loss=1.9076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0, train loss=8.3144\n",
            "Epoch #1, train loss=3.2627\n",
            "Epoch #2, train loss=2.4861\n",
            "Epoch #3, train loss=1.8918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0, train loss=8.0997\n",
            "Epoch #1, train loss=3.2992\n",
            "Epoch #2, train loss=2.5162\n",
            "Epoch #3, train loss=1.9346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0, train loss=8.1814\n",
            "Epoch #1, train loss=3.3488\n",
            "Epoch #2, train loss=2.5194\n",
            "Epoch #3, train loss=1.9140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0, train loss=8.4024\n",
            "Epoch #1, train loss=3.2952\n",
            "Epoch #2, train loss=2.5005\n",
            "Epoch #3, train loss=1.8891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- 10 fold cross validation of the model----\n",
            "0.9527438006206136\n",
            "Category     precision    recall      f1-score      support\n",
            " Arabizi  :  0.91         0.95      0.93        4869  \n",
            " English  :  0.97         0.98      0.97        16938  \n",
            " French   :  0.64         0.44      0.50        167  \n",
            " Arabic   :  0.98         0.99      0.98        2680  \n",
            " Trigger  :  0.76         0.66      0.71        1406  \n",
            " Other    :  0.97         0.94      0.95        4385  \n",
            "micro avg  : 0.95         0.95      0.95        30445 \n",
            "macro avg  : 0.87         0.83      0.84        30445 \n",
            "weighted avg:0.95         0.95      0.95        30445 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating Accuracy and Classification metrics"
      ],
      "metadata": {
        "id": "KIVhfPEtySRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "predicting the tags of given sentence using a given trained model"
      ],
      "metadata": {
        "id": "gFbiSXkcoR_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sentence,model):\n",
        "  model.eval()\n",
        "  tokenized_sentence = tokenizer.encode(sentence)\n",
        "  sen_ids = torch.tensor([tokenized_sentence]).to(device)\n",
        "  state_h, state_c = model.init_state(1)\n",
        "  with torch.no_grad():\n",
        "    segments_ids=torch.tensor([[1]*len(x) for x in sen_ids])\n",
        "    segments_ids=segments_ids.to(device)  \n",
        "    y_pred,_, (state_h, state_c) = model(sen_ids, (state_h, state_c),segments_ids,tags=None)\n",
        "  label_indices=numpy.array(y_pred)\n",
        "\t# join bpe split tokens\n",
        "  tokens = tokenizer.convert_ids_to_tokens(sen_ids.to('cpu').numpy()[0])\n",
        "  new_tokens, new_labels = [], []\n",
        "  for token, label_idx in zip(tokens, label_indices[0]):\n",
        "    if token.startswith(\"##\"):\n",
        "      new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "    else:\n",
        "      new_labels.append(index_to_tag[label_idx])\n",
        "      new_tokens.append(token)\n",
        "  return new_labels[1:-1]\n",
        "  #for token, label in zip(new_tokens, new_labels):\n",
        "    #print(\"{}\\t{}\".format(label, token))\n",
        "labeled_dataset=Dataset(labeled_data)\n",
        "model=Model(embed_size,hidden_size,num_layers,output_dim)\n",
        "train_dl = DataLoader(labeled_dataset,batch_size=BATCH_SIZE,collate_fn=collate_fn)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "total_steps = len(train_dl) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "train(model, optimizer,scheduler, train_dl, max_epochs=epochs)\n"
      ],
      "metadata": {
        "id": "tQAbaUqxoQvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ea15d92-808e-4945-f963-abae8a0f87bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0, train loss=5.5540\n",
            "Epoch #1, train loss=3.1767\n",
            "Epoch #2, train loss=2.1493\n",
            "Epoch #3, train loss=1.4927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "print(predict(\"imagine law tele3na maabaad fel team \",model))\n",
        "print(predict(\"Lava traveled 19km and stopped outside Medina .\",model))\n",
        "print(predict(\"kinda wanted a 4lifer but yall 4everyone\",model))\n",
        "#print(predict(\"the face today in Jerusalem \",model))\n",
        "#print(predict(\"sho had eleshe hogwarts\",model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nA1XYlazRa1",
        "outputId": "3c7c0c49-a6b0-49f5-9a97-2697df0fb134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '1', '0', '0', '0', '1']\n",
            "['1', '1', '5', '1', '1', '1', '4', '5']\n",
            "['1', '1', '1', '0', '1', '0', '0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is for selecting new random sentences and predicting the tags using our trained model, saving the results on a file"
      ],
      "metadata": {
        "id": "m_CxNrMPoffZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import re\n",
        "def preprocess_sentence(s):\n",
        "    # Shorten repeated characters\n",
        "    s = re.sub(r\"(\\w)(\\1){2,}\", r\"\\1\\1\", s)\n",
        "    s=re.sub(r'([ء-ي])([a-zA-Z0-9])',r\"\\1 \\2\",s)\n",
        "    s=re.sub(r'([a-zA-Z0-9])([ء-ي])',r\"\\1 \\2\",s)\n",
        "    s=re.sub(\"/\",\" / \",s)\n",
        "    s=re.sub(\"؟\",\" ؟ \",s)\n",
        "    s=re.sub(\"،\",\" ، \",s)\n",
        "    s=re.sub(\"-\",\" - \",s)\n",
        "    s=re.sub(\"([\\.]+)\",r\" \\1 \",s)\n",
        "    s=re.sub(\"[ ]+\",\" \",s)\n",
        "\n",
        "    return s\n",
        "\n",
        "def select_random_sentences(dir_name,out_file,sample_num):\n",
        "    for file_name in os.listdir(dir_name):\n",
        "        with open(dir_name+'/'+file_name, 'r', encoding=\"utf-8\") as f,open(out_file,'a',encoding=\"utf-8\",newline='') as out:\n",
        "            lines = [line for line in f]\n",
        "            if(len(lines)<sample_num):\n",
        "                continue\n",
        "            random_choice = random.sample(lines[1:], sample_num)\n",
        "            out.writelines(random_choice)\n",
        "\n",
        "\n",
        "# this function chooses new random sentences, a sample_num from each file in dir_name\n",
        "# these sentences are new, i.e aren't already in the csv_file\n",
        "# note that out_file contains all the sentences without annotation\n",
        "#the function prints the final number of the new sentences and annotate only these sentences which will be saved in the annotated file\n",
        "#both files will be downloaded\n",
        "from google.colab import files\n",
        "def choose_new_random_sentences(csv_file, dir_name, out_file, sample_num, clf):\n",
        "    num_of_sentences=0\n",
        "    with open(csv_file, 'r', encoding=\"utf-8\") as f1:\n",
        "        reader = csv.reader(f1)\n",
        "        posts = [row[1] + ',' + row[2] for row in reader]\n",
        "    select_random_sentences(dir_name, out_file, sample_num)\n",
        "    annotated_file = out_file.split('.csv')[0] + '_annotated.csv'\n",
        "    with open(out_file, 'r', encoding=\"utf-8\") as f, open(annotated_file, 'w', encoding=\"utf-8\", newline='') as out:\n",
        "        reader = csv.reader(f)\n",
        "        writer = csv.writer(out, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "        for line in reader:\n",
        "            if line[1] + ',' + line[2] in posts:\n",
        "                continue\n",
        "            preproccessed_sen=preprocess_sentence(line[4])\n",
        "            prediction=predict(preproccessed_sen,clf)\n",
        "            #here I chose from the selected sentences only these who contain Arabizi,English and trigger\n",
        "            if not set(['0','1','4']).issubset(set(prediction)) :\n",
        "                continue\n",
        "            for w,pred in zip(str.split(preproccessed_sen),prediction):\n",
        "              writer.writerow([line[0], line[1], line[3], w, pred])\n",
        "            num_of_sentences+=1\n",
        "    files.download(out_file)\n",
        "    files.download(annotated_file)\n",
        "    #printing the number of annotated sentences (note that this is not equal to number of sentences in out_file)\n",
        "    print(num_of_sentences)\n",
        "\n",
        "#choose_new_random_sentences('/content/Arabizi-project/words_annotated.csv','/content/Arabizi-project/reddit_subreddits','/content/Arabizi-project/random_trigger_reddit.csv',20,model)\n",
        "#choose_new_random_sentences('/content/Arabizi-project/words_annotated.csv','/content/Arabizi-project/all_users_tokenized','/content/Arabizi-project/random_trigger_CS_twitter.csv',10,model)\n"
      ],
      "metadata": {
        "id": "dtSCF91Hhf-5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}